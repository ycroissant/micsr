@article{ROME:99,
author = {Romeo, Charles J.},
title = {Conducting inference in semiparametric duration models under inequality restrictions on the shape of the hazard implied by job search theory},
journal = {Journal of Applied Econometrics},
volume = {14},
number = {6},
pages = {587-605},
doi = {https://doi.org/10.1002/(SICI)1099-1255(199911/12)14:6<587::AID-JAE541>3.0.CO;2-R},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-1255%28199911/12%2914%3A6%3C587%3A%3AAID-JAE541%3E3.0.CO%3B2-R},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291099-1255%28199911/12%2914%3A6%3C587%3A%3AAID-JAE541%3E3.0.CO%3B2-R},
abstract = {Abstract Using a four-month panel of revised Current Population Survey data from September–December 1993, we extend the class of semiparametric hazard models of the type first studied by Prentice and Gloeckler (1978), and brought to the attention of economists by Meyer (1988, 1990), to incorporate inequality restrictions on the shape of the hazard. This extension enables us to test hypotheses regarding the shape of the hazard implied by search theory using duration data alone. These tests provide another link between the empirical and theoretical literatures on unemployment duration and job search. The GHK probability simulator makes it straightforward to generate approximate hypothesis test results, as simulation estimates of the probability under the null hypothesis are generated using the asymptotic normal approximation to the distribution of the hazard parameters obtained from maximum likelihood estimation. Importance sampling is used to conduct inference under the null and obtain exact finite sample estimates of the probability the null is satisfied. A new algorithm for maintaining stability of the importance weights is also developed. Copyright © 1999 John Wiley \& Sons, Ltd.},
year = {1999}
}

@article{WICH:WILK:08,
author = {Wichert, Laura and Wilke, Ralf A.},
title = {Simple non-parametric estimators for unemployment duration analysis},
journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
volume = {57},
number = {1},
pages = {117-126},
keywords = {Censoring, Non-parametric estimation, Unemployment duration},
doi = {https://doi.org/10.1111/j.1467-9876.2007.00604.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9876.2007.00604.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9876.2007.00604.x},
abstract = {Summary.  We consider an extension of conventional univariate Kaplan–Meier-type estimators for the hazard rate and the survivor function to multivariate censored data with a censored random regressor. It is an Akritas-type estimator which adapts the non-parametric conditional hazard rate estimator of Beran to more typical data situations in applied analysis. We show with simulations that the estimator has nice finite sample properties and our implementation appears to be fast. As an application we estimate non-parametric conditional quantile functions with German administrative unemployment duration data.},
year = {2008}
}

@article{TERZ:98,
  author={Terza, Joseph V.},
  title={{Estimating count data models with endogenous switching: Sample selection and endogenous treatment effects}},
  journal={Journal of Econometrics},
  year=1998,
  volume={84},
  number={1},
  pages={129-154},
  month={May},
  keywords={},
  doi={},
  abstract={No abstract is available for this item.},
  url={https://ideas.repec.org/a/eee/econom/v84y1998i1p129-154.html}
}

@article{WYSZ:MARR:18,
  author={Karol Wyszynski and Giampiero Marra},
  title={{Sample selection models for count data in R}},
  journal={Computational Statistics},
  year=2018,
  volume={33},
  number={3},
  pages={1385-1412},
  month={September},
  keywords={Copula; Non-random sample selection; Penalized regression spline; Selection bias; Count response; Tu},
  doi={10.1007/s00180-017-0762-y},
  abstract={ We provide a detailed hands-on tutorial for the R package SemiParSampleSel (version 1.5). The package implements selection models for count responses fitted by penalized maximum likelihood estimation. The approach can deal with non-random sample selection, flexible covariate effects, heterogeneous selection mechanisms and varying distributional parameters. We provide an overview of the theoretical background and then demonstrate how SemiParSampleSel can be used to fit interpretable models of different complexity. We use data from the German Socio-Economic Panel survey (SOEP v28, 2012. doi: 10.5684/soep.v28 ) throughout the tutorial.},
  url={https://ideas.repec.org/a/spr/compst/v33y2018i3d10.1007_s00180-017-0762-y.html}
}


@article{HECK:79,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1912352},
 abstract = {This paper discusses the bias that results from using nonrandomly selected samples to estimate behavioral relationships as an ordinary specification error or "omitted variables" bias. A simple consistent two stage estimator is considered that enables analysts to utilize simple regression methods to estimate behavioral functions by least squares methods. The asymptotic distribution of the estimator is derived.},
 author = {James J. Heckman},
 journal = {Econometrica},
 number = {1},
 pages = {153--161},
 publisher = {[Wiley, Econometric Society]},
 title = {Sample Selection Bias as a Specification Error},
 urldate = {2022-05-25},
 volume = {47},
 year = {1979}
}

@TechReport{GREE:94,
  author={William H. Greene},
  title={{Accounting for Excess Zeros and Sample Selection in Poisson and Negative Binomial Regression Models}},
  year=1994,
  month=,
  institution={New York University, Leonard N. Stern School of Business, Department of Economics},
  type={Working Papers},
  url={https://ideas.repec.org/p/ste/nystbu/94-10.html},
  number={94-10},
  abstract={No abstract is available for this item.},
  keywords={},
  doi={},
}

@Inbook{GREE:01,
author="Greene, William H.",
editor="Negishi, Takashi
and Ramachandran, Rama V.
and Mino, Kazuo",
chapter = "6",
title="Fiml Estimation of Sample Selection Models for Count Data",
bookTitle="Economic Theory, Dynamics and Markets: Essays in Honor of Ryuzo Sato",
year="2001",
publisher="Springer US",
address="Boston, MA",
pages="73--91",
abstract="The econometric issue of sample selection concerns the possible biases that arise when a nonrandomly sampled set of observations from a population is used as if the sample were random to make inferences about that population. Current literature, with a few exceptions noted below, has focused on, and finely tuned, the known results relating to this issue in the framework of the linear regression model and analysis of a continuous dependent variable, such as hours worked or wages. This paper will examine an extension of the sample selection model to the Poisson regression model for discrete, count data, such as numbers of patents, of children, of visits to facilities such as shops or recreation sites, of convictions for crimes committed, and so on.",
isbn="978-1-4615-1677-4",
doi="10.1007/978-1-4615-1677-4_6",
url="https://doi.org/10.1007/978-1-4615-1677-4_6"
}

@article{KENK:TERZ:01,
author = {Kenkel, Donald S. and Terza, Joseph V.},
title = {The effect of physician advice on alcohol consumption: count regression with an endogenous treatment effect},
journal = {Journal of Applied Econometrics},
volume = {16},
number = {2},
pages = {165-184},
doi = {https://doi.org/10.1002/jae.596},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.596},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.596},
abstract = {Abstract Although there are encouraging trends, alcohol abuse continues to be a significant public health problem. Econometric studies of alcohol demand have yielded a great deal of information for alcohol abuse prevention policy. These studies suggest that higher alcohol taxes and stricter drunk-driving policies can reduce heavy drinking and drunk driving. In this paper we explore the role physician advice plays in the campaign to prevent alcohol-related problems. Compared to alcohol taxation, physician advice is a more precisely targeted intervention that does not impose extra costs on responsible drinkers. Compared to the resource costs of arresting, processing, and punishing drunk drivers, physician advice may be a lower-cost intervention. To provide a basis for alcohol policy analysis, we use an alcohol demand framework to test whether physician-provided information about the adverse consequences of alcohol abuse shifts demand to more moderate levels. There are three aspects of our alcohol demand model that complicate the estimation: (1) the dependent variable is non-negative (it is a count variable—number of drinks consumed); (2) a non-trivial number of sample observations have zero values for the dependent variable; and (3) because the data we use is non-experimental, the treatment variable indicating receipt of advice from a physician may be endogenous. We implement an estimation method that is specifically designed to deal with these three complicating factors. Our results show that advice has a substantial and significant impact on alcohol consumption by males with hypertension, and that failing to account for the endogeneity of advice masks this result. Copyright © 2001 John Wiley \& Sons, Ltd.},
year = {2001}
}

@article{TERZ:WILS:90,
  author={Terza, Joseph V and Wilson, Paul W},
  title={{Analyzing Frequencies of Several Types of Events: A Mixed Multinomial-Poisson Approach}},
  journal={The Review of Economics and Statistics},
  year=1990,
  volume={72},
  number={1},
  pages={108-115},
  month={February},
  abstract={ A flexible, generalized Poisson model is combined with the multinomial distribution to jointly predict households' choices among types of trips and frequency of trips. The model is compared with conventional Poisson models. The problem of a time-variant mean for frequencies is also addressed, as well as the mean-variance property of the conventional Poisson model that is avoided by use of the generalized formulation. The generalized model is found to outperform the conventional models. Copyright 1990 by MIT Press.},
  url={https://ideas.repec.org/a/tpr/restat/v72y1990i1p108-15.html}
}

@InCollection{HECK:76,
  author={James J. Heckman},
  title={{The Common Structure of Statistical Models of Truncation, Sample Selection and Limited Dependent Variables and a Simple Estimator for Such Models}},
  booktitle={{Annals of Economic and Social Measurement, Volume 5, number 4}},
  publisher={National Bureau of Economic Research, Inc},
  year=1976,
  month={May},
  volume={},
  number={},
  series={NBER Chapters},
  edition={},
  chapter={},
  pages={475-492},
  doi={},
  keywords={},
  abstract={No abstract is available for this item.},
  url={https://ideas.repec.org/h/nbr/nberch/10491.html}
}

@ARTICLE{AMEM:78,
title = {The Estimation of a Simultaneous Equation Generalized Probit Model},
author = {Amemiya, Takeshi},
year = {1978},
journal = {Econometrica},
volume = {46},
number = {5},
pages = {1193-1205},
url = {https://EconPapers.repec.org/RePEc:ecm:emetrp:v:46:y:1978:i:5:p:1193-1205}
}

@ARTICLE{AMEM:79,
title = {The Estimation of a Simultaneous-Equation Tobit Model},
author = {Amemiya, Takeshi},
year = {1979},
journal = {International Economic Review},
volume = {20},
number = {1},
pages = {169-81},
url = {https://EconPapers.repec.org/RePEc:ier:iecrev:v:20:y:1979:i:1:p:169-81}
}

@article{NEWE:87,
title = {Efficient estimation of limited dependent variable models with endogenous explanatory variables},
journal = {Journal of Econometrics},
volume = {36},
number = {3},
pages = {231-250},
year = {1987},
issn = {0304-4076},
doi = {https://doi.org/10.1016/0304-4076(87)90001-7},
url = {https://www.sciencedirect.com/science/article/pii/0304407687900017},
author = {Whitney K. Newey},
abstract = {This paper discusses asymptotically efficient estimation of the parameters of limited dependent variable models with endogenous explanatory variables. General results on asymptotic efficiency of two-stage and Amemiya GLS estimators are derived and used to obtain a simple, asymptotically efficient estimator of the structural coefficients. This estimator can be calculated by applying GLS to estimates of the reduced form coefficients that are obtained by using reduced form residuals as additional explanatory variables. It is also shown that it is possible to obtain asymptotically efficient estimators of the other coefficients by a modified minimum chi-square method.}
}

@ARTICLE{RIVE:VUON:88,
title = {Limited information estimators and exogeneity tests for simultaneous probit models},
author = {Rivers, Douglas and Vuong, Quang H.},
year = {1988},
journal = {Journal of Econometrics},
volume = {39},
number = {3},
pages = {347-366},
url = {https://EconPapers.repec.org/RePEc:eee:econom:v:39:y:1988:i:3:p:347-366}
}


@ARTICLE{SMIT:BLUN:86,
title = {An Exogeneity Test for a Simultaneous Equation Tobit Model with an Application to Labor Supply},
author = {Smith, Richard and Blundell, Richard},
year = {1986},
journal = {Econometrica},
volume = {54},
number = {3},
pages = {679-85},
url = {https://EconPapers.repec.org/RePEc:ecm:emetrp:v:54:y:1986:i:3:p:679-85}
}


@Article{ADKI:CART:SIMP:07,
  author={Lee C. Adkins and David A. Carter and W. Gary Simpson},
  title={{Managerial Incentives And The Use Of Foreign‐Exchange Derivatives By Banks}},
  journal={Journal of Financial Research},
  year=2007,
  volume={30},
  number={3},
  pages={399-413},
  month={September},
  keywords={},
  doi={10.1111/j.1475-6803.2007.},
  abstract={We examine the effect of managerial compensation and ownership on the use of foreign‐exchange derivatives by U.S. bank holding companies. We focus on derivatives used for purposes other than trading to investigate derivative use in a hedging framework. We use instrumental variables probit and sample‐selection models to estimate the effects of endogenous and exogenous factors on the probability and extent of foreign‐exchange derivatives used. We find that the use of derivatives is inversely related to option awards but positively related to managerial ownership. Finally, our results suggest that ownership by large institutional shareholders provides incentive for managers to hedge.},
  url={https://ideas.repec.org/a/bla/jfnres/v30y2007i3p399-413.html}
}

@article{ADKI:12,
author = { Lee   C.   Adkins },
title = {Testing parameter significance in instrumental variables probit estimators: some simulation},
journal = {Journal of Statistical Computation and Simulation},
volume = {82},
number = {10},
pages = {1415-1436},
year  = {2012},
publisher = {Taylor & Francis},
doi = {10.1080/00949655.2011.580344},

URL = { 
        https://doi.org/10.1080/00949655.2011.580344
    
},
eprint = { 
        https://doi.org/10.1080/00949655.2011.580344   
}
}


@article{MULL:97,
    author = {Mullahy, John},
    title = "{Instrumental-Variable Estimation of Count Data Models: Applications to Models of Cigarette Smoking Behavior}",
    journal = {The Review of Economics and Statistics},
    volume = {79},
    number = {4},
    pages = {586-593},
    year = {1997},
    month = {11},
    abstract = "{As with most analyses involving microdata, applications of count data models must somehow account for unobserved heterogeneity. The count model literature has generally assumed that unobservables and observed covariates are statistically independent. Yet for many applications this independence assumption is clearly tenuous. When the unobservables are omitted variables correlated with included regressors, standard estimation methods will generally be inconsistent. Though alternative consistent estimators may exist in special circumstances, it is suggested here that a nonlinear instrumental-variable strategy offers a reasonably general solution to such estimation problems. This approach is applied in two examples that focus on cigarette smoking behavior.}",
    issn = {0034-6535},
    doi = {10.1162/003465397557169},
    url = {https://doi.org/10.1162/003465397557169},
    eprint = {https://direct.mit.edu/rest/article-pdf/79/4/586/1612341/003465397557169.pdf},
}

@article{WILH:08,
author = {Wilhelm, Mark Ottoni},
title = {Practical Considerations for Choosing Between Tobit and SCLS or CLAD Estimators for Censored Regression Models with an Application to Charitable Giving},
journal = {Oxford Bulletin of Economics and Statistics},
volume = {70},
number = {4},
pages = {559-582},
keywords = {C12, C14, C15, C24, C52},
doi = {https://doi.org/10.1111/j.1468-0084.2008.00506.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0084.2008.00506.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1468-0084.2008.00506.x},
abstract = {Abstract Practical considerations for choosing between Tobit, symmetrically censored least squares (SCLS) and censored least absolute deviations (CLAD) estimators are offered. Practical considerations deal with when a Hausman test is better than a conditional moment test for judging the severity of a misspecification, the need to bootstrap the sampling distributions of the Hausman tests, what to look for in a graphical examination of the residuals and the limited value of SCLS. The practical considerations are applied to a model of the intergenerational transmission of charitable giving using new data from the Panel Study of Income Dynamics (PSID). The paper shows how to use relative distribution methods to calculate CLAD-based marginal effects on the observable dependent variable.},
year = {2008}
}

@Article{POWE:86,
  author = 	 {Powell, J.},
  title = 	 {Symmetrically trimed least squares estimators for tobit models},
  journal = 	 {Econometrica},
  year = 	 {1986},
  OPTkey = 	 {},
  volume = 	 {54},
  OPTnumber = 	 {},
  pages = 	 {1435--1460},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}


@article{DRUK:02,
author = {David M. Drukker},
title ={Bootstrapping a Conditional Moments Test for Normality after Tobit Estimation},
journal = {The Stata Journal},
volume = {2},
number = {2},
pages = {125-139},
year = {2002},
doi = {10.1177/1536867X0200200202},

URL = { 
        https://doi.org/10.1177/1536867X0200200202
    
},
eprint = { 
        https://doi.org/10.1177/1536867X0200200202
    
}
,
    abstract = { Categorical and limited dependent variable models are routinely estimated via maximum likelihood. It is well-known that the ML estimates of the parameters are inconsistent if the distribution or the skedastic component is misspecified. When conditional moment tests were first developed by Newey (1985) and Tauchen (1985), they appeared to offer a wide range of easy-to-compute specification tests for categorical and limited dependent variable models estimated by maximum likelihood. However, subsequent studies found that using the asymptotic critical values produced severe size distortions. This paper presents simulation evidence that the standard conditional moment test for normality after tobit estimation has essentially no size distortion and reasonable power when the critical values are obtained via a parametric bootstrap. }
}


@article{SKEE:VELL:99,
title = {A Monte Carlo investigation of the sampling behavior of conditional moment tests in Tobit and Probit models},
journal = {Journal of Econometrics},
volume = {92},
number = {2},
pages = {275-294},
year = {1999},
issn = {0304-4076},
doi = {https://doi.org/10.1016/S0304-4076(98)00092-X},
url = {https://www.sciencedirect.com/science/article/pii/S030440769800092X},
author = {Christopher L. Skeels and Francis Vella},
keywords = {Generalized residuals, Conditional moment tests, Tobit, Probit},
abstract = {This paper provides a Monte Carlo examination of conditional moment tests for several forms of misspecification in Tobit and Probit models. The experimental design is based on actual data taken from a study of labor supply. Our results indicate that the tests work well, in terms of size and power, for the Tobit model whereas they perform poorly for the Probit model. The major conclusion is that although there is little to choose between the various forms of the tests the degree of censoring of the latent dependent variable is crucial.}
}

@article{MOFF:84,
 ISSN = {0734306X, 15375307},
 URL = {https://www.jstor.org/stable/2534814},
 abstract = {In this paper the standard cross-sectional static model of labor supply is modified to make the wage endogenous, and a joint wage-hours model is estimated. The econometric technique addresses the non-linearity of the budget constraint by approximating the constraint by a series of discrete points. The results show that the budget constraint is indeed nonlinear, that hours affect the wage quadratically, that true wage elasticities are lower as a result, and that the model fits the hours distribution much better than the standard Tobit model.},
 author = {Robert Moffitt},
 journal = {Journal of Labor Economics},
 number = {4},
 pages = {550--566},
 publisher = {[University of Chicago Press, Society of Labor Economists, NORC at the University of Chicago]},
 title = {The Estimation of a Joint Wage-Hours Labor Supply Model},
 volume = {2},
 year = {1984}
}

@article{MATS:SHER:06,
Author = {Matschke, Xenia and Sherlund, Shane M.},
Title = {Do Labor Issues Matter in the Determination of U.S. Trade Policy? An Empirical Reevaluation},
Journal = {American Economic Review},
Volume = {96},
Number = {1},
Year = {2006},
Month = {March},
Pages = {405-421},
DOI = {10.1257/000282806776157524},
URL = {https://www.aeaweb.org/articles?id=10.1257/000282806776157524}}


@article{HAUS:78,
 ISSN = {00129682, 14680262},
 URL = {https://www.jstor.org/stable/1913827},
 abstract = {Using the result that under the null hypothesis of no misspecification an asymptotically efficient estimator must have zero asymptotic covariance with its difference from a consistent but asymptotically inefficient estimator, specification tests are devised for a number of model specifications in econometrics. Local power is calculated for small departures from the null hypothesis. An instrumental variable test as well as tests for a time series cross section model and the simultaneous equation model are presented. An empirical model provides evidence that unobserved individual factors are present which are not orthogonal to the included right-hand-side variable in a common econometric specification of an individual wage equation.},
 author = {J. A. Hausman},
 journal = {Econometrica},
 number = {6},
 pages = {1251--1271},
 publisher = {[Wiley, Econometric Society]},
 title = {Specification Tests in Econometrics},
 volume = {46},
 year = {1978}
}


@article{NEWE:85,
 ISSN = {00129682, 14680262},
 URL = {https://www.jstor.org/stable/1911011},
 abstract = {This paper examines the detection of misspecification in the context of maximum likelihood models. The power properties of specification tests based on moment conditions are explicitly considered. Tests of conditional moment restrictions are also discussed and are shown to be particularly useful when exogenous variables are present. The form of optimal conditional moment tests is presented. The general results are then applied to specification tests for probit.},
 author = {Whitney K. Newey},
 journal = {Econometrica},
 number = {5},
 pages = {1047--1070},
 publisher = {[Wiley, Econometric Society]},
 title = {Maximum Likelihood Specification Testing and Conditional Moment Tests},
 volume = {53},
 year = {1985}
}

@article{TAUC:85,
title = {Diagnostic testing and evaluation of maximum likelihood models},
journal = {Journal of Econometrics},
volume = {30},
number = {1},
pages = {415-443},
year = {1985},
issn = {0304-4076},
doi = {https://doi.org/10.1016/0304-4076(85)90149-6},
url = {https://www.sciencedirect.com/science/article/pii/0304407685901496},
author = {George Tauchen},
abstract = {The paper develops a unified theory of likelihood
                  specification testing based on M-estimators of
                  auxiliary parameters. The theory is sufficiently
                  general to encompass a wide class of specification
                  tests including moment-based tests, Pearson-type
                  goodness of fit tests, the information matrix test,
                  and the Cox test. The paper also presents a
                  framework based on Frechet differentiation for
                  determining the effects of misspecification on the
                  almost sure limits of parameter estimates and
                  specification test statistics.}
}

@article{WELL:03,
 ISSN = {08837252, 10991255},
 URL = {https://www.jstor.org/stable/30035205},
 abstract = {Modern econometrics stresses the diagnostic testing of estimated models as an important part of the modelbuilding process. In a survey article published in this journal (Pagan and Vella, 1989), methods for testing the validity of the assumptions underlying the censored regression of the Tobit model were presented. This paper questions the numerical results presented there. Indeed, my results concerning the tests when applied to Fair's well-known model for infidelity (1978) are the opposite of those presented in this journal.},
 author = {Curt Wells},
 journal = {Journal of Applied Econometrics},
 number = {2},
 pages = {237--239},
 publisher = {Wiley},
 title = {Retesting Fair's (1978) Model on Infidelity},
 volume = {18},
 year = {2003}
}

@article{PAGA:VELL:89,
 ISSN = {08837252, 10991255},
 URL = {https://www.jstor.org/stable/2096593},
 abstract = {This paper surveys the growing literature on diagnostic testing of models based on unit record data. We argue that while many of these tests are produced in a Lagrange multiplier framework they are often more readily derived, and more easily applied, if approached from the conditional moment testing view of Newey (1985) and Tauchen (1985). In addition we propose some new tests based on comparisons of parametric estimators with nonparametric estimators which are consistent under certain forms of misspecification. To illustrate the utility of the tests we employ them in the examination of some existing published studies.},
 author = {Adrian Pagan and Frank Vella},
 journal = {Journal of Applied Econometrics},
 number = {},
 pages = {S29--S59},
 publisher = {Wiley},
 title = {Diagnostic Tests for Models Based on Individual Data: A Survey},
 volume = {4},
 year = {1989}
}


@article{FAVE:PESA:SHAR:94,
 ISSN = {08837252, 10991255},
 URL = {http://www.jstor.org/stable/2285225},
 abstract = {The aim of this paper is to analyse the implications of the theory of irreversible investment under uncertainty for investment in oil fields on the United Kingdom Continental Shelf (UKCS). We consider the problem of an operator who owns a licence to develop and extract oil from a field of known capacity. An intertemporal optimization model in discrete time is developed to derive decision rules for the timing of the irreversible development investment and for the optimal rate of extraction. Model simulation is then used to describe the properties of the numerical solutions. The predictions of the theory on the determinants of the irreversible investment decision are then examined using statistical duration analysis. Data on the length of the time period between discovery and development are available for individual fields on the UKCS. We measure the duration of the irreversible investment gestation lag for each field and test the model by assessing the significance of the theoretical variables in explaining the significance of such a lag. Both our theoretical model and our empirical results suggest the importance of a nonlinear interaction of the level of oil prices and the volatility of oil prices in determining the development lag. The simulation of our theoretical model shows a nonlinear impact of oil price volatility on the trigger level of oil prices. Our empirical results suggest that the effect of price volatility is a function of the expected price level, with increased price volatility having a positive impact on the duration of investment appraisal when expected prices are low and a negative impact when they are high.},
 author = {Carlo A. Favero and M. Hashem Pesaran and Sunil Sharma},
 journal = {Journal of Applied Econometrics},
 number = {},
 pages = {S95--S112},
 publisher = {Wiley},
 title = {A Duration Model of Irreversible Oil Investment: Theory and Empirical Evidence},
 volume = {9},
 year = {1994}
}



@article{MILL:09,
Author = {Miller, Nathan H.},
Title = {Strategic Leniency and Cartel Enforcement},
Journal = {American Economic Review},
Volume = {99},
Number = {3},
Year = {2009},
Month = {June},
Pages = {750-68},
DOI = {10.1257/aer.99.3.750},
URL = {https://www.aeaweb.org/articles?id=10.1257/aer.99.3.750}}



@article{ANGR:90,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/2006669},
 abstract = {The randomly assigned risk of induction generated by the draft lottery is used to construct estimates of the effect of veteran status on civilian earnings. These estimates are not biased by the fact that certain types of men are more likely than others to service in the military. Social Security administrative records indicate that in the early 1980s, long after their service in Vietnam was ended, the earnings of white veterans were approximately 15 percent less than the earnings of comparable nonveterans.},
 author = {Joshua D. Angrist},
 journal = {The American Economic Review},
 number = {3},
 pages = {313--336},
 publisher = {American Economic Association},
 title = {Lifetime Earnings and the Vietnam Era Draft Lottery: Evidence from Social Security Administrative Records},
 volume = {80},
 year = {1990}
}


@article{COST:MITT:MCCL:09,
author = {Costanigro, Marco and Mittelhammer, Ron C. and McCluskey, Jill J.},
title = {Estimating class-specific parametric models under class uncertainty: local polynomial regression clustering in an hedonic analysis of wine markets},
journal = {Journal of Applied Econometrics},
volume = {24},
number = {7},
pages = {1117-1135},
doi = {https://doi.org/10.1002/jae.1094},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.1094},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.1094},
abstract = {Abstract We introduce a method for estimating multiple class regression models when class membership is uncertain. The procedure—local polynomial regression clustering—first estimates a nonparametric model via local polynomial regression, and then identifies the underlying classes by aggregating sample observations into data clusters with similar estimates of the (local) functional relationships between dependent and independent variables. Finally, parametric functions specific to each class are estimated. The technique is applied to the estimation of a multiple-class hedonic model for wine, resulting in the identification of four distinct wine classes based on differences in implicit prices of the attributes. Copyright © 2009 John Wiley \& Sons, Ltd.},
year = {2009}
}

@article{MAKO:STRA:09,
Author = {Makowsky, Michael D. and Stratmann, Thomas},
Title = {Political Economy at Any Speed: What Determines Traffic Citations?},
Journal = {American Economic Review},
Volume = {99},
Number = {1},
Year = {2009},
Month = {March},
Pages = {509-27},
DOI = {10.1257/aer.99.1.509},
URL = {https://www.aeaweb.org/articles?id=10.1257/aer.99.1.509}}


@Article{MANK:ROME:WEIL:92,
  author={N. Gregory Mankiw and David Romer and David N. Weil},
  title={{A Contribution to the Empirics of Economic Growth}},
  journal={The Quarterly Journal of Economics},
  year=1992,
  volume={107},
  number={2},
  pages={407-437},
  month={},
  keywords={},
  doi={},
  abstract={This paper examines whether the Solow growth model is consistent with the international variation in the standard of living. It shows that an augmented Solow model that includes accumulation of human as well as physical capital provides an excellent description of the cross-country data. The paper also examines the implications of the Solow model for convergence in standards of living, that is, for whether poor countries tend to grow faster than rich countries. The evidence indicates that, holding population growth and capital accumulation constant, countries converge at about the rate the augmented Solow model predicts.},
  url={https://ideas.repec.org/a/oup/qjecon/v107y1992i2p407-437..html}
}

@Book{BONN:04,
  author = 	 {Bonnel, Patrick},
  ALTeditor = 	 {},
  title = 	 {Prévoir la demande de transports},
  publisher = 	 {Presses de l'école nationale des ponts et chaussées},
  year = 	 {2004},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}


@article{ANAN:11,
Author = {Ananat, Elizabeth Oltmans},
Title = {The Wrong Side(s) of the Tracks: The Causal Effects of Racial Segregation on Urban Poverty and Inequality},
Journal = {American Economic Journal: Applied Economics},
Volume = {3},
Number = {2},
Year = {2011},
Month = {April},
Pages = {34-66},
DOI = {10.1257/app.3.2.34},
URL = {https://www.aeaweb.org/articles?id=10.1257/app.3.2.34}}



@article{HOCH:03,
author = {Hochguertel, Stefan},
title = {Precautionary motives and portfolio decisions},
journal = {Journal of Applied Econometrics},
volume = {18},
number = {1},
pages = {61-77},
doi = {https://doi.org/10.1002/jae.658},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.658},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.658},
abstract = {Abstract This paper studies the empirical relevance of precautionary and other motives for household portfolio behaviour using recent panel data from the Netherlands. Dutch households' portfolios exhibit low degrees of risk taking and diversification. It is possible that this is the outcome of a rational, precautionary response to unavoidable exposure to background risk (stemming from the labour market or health conditions, etc.). We consider as alternative explanations liquidity needs and habits. The endogenous variable is the fraction of clearly safe in total financial assets at the household level. Parametric and semi-parametric censored regression models for pooled cross-sections and random and fixed effects models for panel data show that both heteroscedasticity and unobserved heterogeneity are of major importance in the data. With subjective indicators of income uncertainty we find a limited role for precautionary motives. Copyright © 2002 John Wiley \& Sons, Ltd.},
year = {2003}
}

@article{CROM:PALM:URBA:97,
author = {De Crombrugghe, Denis and Palm, Franz C. and Urbain, Jean-Pierre},
title = {Statistical demand functions for food in the USA and the Netherlands},
journal = {Journal of Applied Econometrics},
volume = {12},
number = {5},
pages = {615-645},
doi = {https://doi.org/10.1002/(SICI)1099-1255(199709/10)12:5<615::AID-JAE455>3.0.CO;2-L},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-1255%28199709/10%2912%3A5%3C615%3A%3AAID-JAE455%3E3.0.CO%3B2-L},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291099-1255%28199709/10%2912%3A5%3C615%3A%3AAID-JAE455%3E3.0.CO%3B2-L},
abstract = {Abstract This paper reports results of an extensive analysis of statistical demand functions for food using household survey data and aggregate time-series data on food consumption in the USA and The Netherlands. Using the model put forward by Tobin (1950) for survey data, we find that socio-economic information on the composition, education, and status of households adds little to the explanation of food consumption. The income elasticity of food consumption decreases over time in the USA but increases in The Netherlands. Applying multivariate cointegration analysis to the time-series data, we find that strict price homogeneity, structural stability, and weak exogeneity of prices have to be rejected statistically at conventional significance levels, whereas weak exogeneity of food consumption cannot be rejected. The long-run income elasticity tends to decrease over time for US data and is roughly constant for Dutch data. The findings corroborate earlier findings for the survey data. The rejection of price exogeneity is consistent with Tobin's model which treats prices as endogenous. © 1997 John Wiley \& Sons, Ltd.},
year = {1997}
}


@article{CAME:TRIV:MILN:PIGG:88,
 ISSN = {00346527, 1467937X},
 URL = {http://www.jstor.org/stable/2297531},
 abstract = {This paper develops a model for interdependent demand for health insurance and health care under uncertainty to throw light on the issue of insurance-induced distortions in the demand for health care services. The model is used to empirically analyse the determinants of the choice of health insurance type and seven types of health care services using micro-level data from the 1977-78 Australian Health Survey. Econometric implementation of the model involves, simultaneously, issues of discreteness of choice, selectivity and stochastic dependence between health insurance and utilization. Health status appears to be more important in determining health care service use than health insurance choice, while income appears to be more important in determining health insurance choice than in determining health care service use. For a broad range of health care services both moral hazard and self selection are found to be important determinants of utilization of health care services.},
 author = {A. C. Cameron and P. K. Trivedi and Frank Milne and J. Piggott},
 journal = {The Review of Economic Studies},
 number = {1},
 pages = {85--106},
 publisher = {[Oxford University Press, Review of Economic Studies, Ltd.]},
 title = {A Microeconometric Model of the Demand for Health Care and Health Insurance in Australia},
 urldate = {2022-07-14},
 volume = {55},
 year = {1988}
}


@book{CAME:TRIV:13,
  place={Cambridge},
  edition={2},
  series={Econometric Society Monographs},
  title={Regression Analysis of Count Data},
  DOI={10.1017/CBO9781139013567},
  publisher={Cambridge University Press},
  author={Cameron, A. Colin and Trivedi, Pravin K.},
  year={2013},
  collection={Econometric Society Monographs}
}

@article{CAME:JOHA:97,
author = {CAMERON, A. COLIN and JOHANSSON, PER},
title = {COUNT DATA REGRESSION USING SERIES EXPANSIONS: WITH APPLICATIONS},
journal = {Journal of Applied Econometrics},
volume = {12},
number = {3},
pages = {203-223},
doi = {https://doi.org/10.1002/(SICI)1099-1255(199705)12:3<203::AID-JAE446>3.0.CO;2-2},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-1255%28199705%2912%3A3%3C203%3A%3AAID-JAE446%3E3.0.CO%3B2-2},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291099-1255%28199705%2912%3A3%3C203%3A%3AAID-JAE446%3E3.0.CO%3B2-2},
abstract = {Abstract A new class of parametric regression models for both under- and overdispersed count data is proposed. These models are based on squared polynomial expansions around a Poisson baseline density. The approach is similar to that for continuous data using squared Hermite polynomials proposed by Gallant and Nychka and applied to financial data by, among others, Gallant and Tauchen. The count models are applied to underdispersed data on the number of takeover bids received by targeted firms, and to overdispersed data on the number of visits to health practitioners. The models appear to be particularly useful for underdispersed count data. © 1997 John Wiley \& Sons, Ltd.},
year = {1997}
}

@article{CAME:TRIV:86,
author = {Cameron, A. Colin and Trivedi, Pravin K.},
title = {Econometric models based on count data. Comparisons and applications of some estimators and tests},
journal = {Journal of Applied Econometrics},
volume = {1},
number = {1},
pages = {29-53},
doi = {https://doi.org/10.1002/jae.3950010104},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.3950010104},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.3950010104},
abstract = {Abstract This paper deals with specification, estimation and tests of single equation reduced form type equations in which the dependent variable takes only non-negative integer values. Beginning with Poisson and compound Poisson models, which involve strong assumptions, a variety of possible stochastic models and their implications are discussed. A number of estimators and their properties are considered in the light of uncertainty about the data generation process. The paper also considers the role of tests in sequential revision of the model specification beginr ing with the Poisson case and provides a detailed application of the estimators and tests to a model of the number of doctor consultations.},
year = {1986}
}


@Book{MADD:01,
  author = 	 {Maddala, G.S.},
  ALTeditor = 	 {},
  title = 	 {Introduction to Econometrics},
  publisher = 	 {Wiley},
  year = 	 {2001},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  edition = 	 {3},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@article{KOOP:POIR:TOBI:05,
author = {Koop, Gary and Poirier, Dale J. and Tobias, Justin},
title = {Semiparametric Bayesian inference in multiple equation models},
journal = {Journal of Applied Econometrics},
volume = {20},
number = {6},
pages = {723-747},
doi = {https://doi.org/10.1002/jae.810},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.810},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.810},
abstract = {Abstract This paper outlines an approach to Bayesian semiparametric regression in multiple equation models which can be used to carry out inference in seemingly unrelated regressions or simultaneous equations models with nonparametric components. The approach treats the points on each nonparametric regression line as unknown parameters and uses a prior on the degree of smoothness of each line to ensure valid posterior inference despite the fact that the number of parameters is greater than the number of observations. We develop an empirical Bayesian approach that allows us to estimate the prior smoothing hyperparameters from the data. An advantage of our semiparametric model is that it is written as a seemingly unrelated regressions model with independent normal–Wishart prior. Since this model is a common one, textbook results for posterior inference, model comparison, prediction and posterior computation are immediately available. We use this model in an application involving a two-equation structural model drawn from the labour and returns to schooling literatures. Copyright © 2005 John Wiley \& Sons, Ltd.},
year = {2005}
}

@Article{HORO:93,
  author = 	 {Horowitz, Joel L.},
  title = 	 {Semiparametric estimation of a work-trip mode choice model},
  journal = 	 {Journal of econometrics},
  year = 	 {1993},
  OPTkey = 	 {},
  volume = 	 {58},
  number = 	 {1-2},
  pages = 	 {49-70},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}


@article{BERT:MULL:04,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/3592802},
 abstract = {We study race in the labor market by sending fictitious resumes to help-wanted ads in Boston and Chicago newspapers. To manipulate perceived race, resumes are randomly assigned African-American- or White-sounding names. White names receive 50 percent more callbacks for interviews. Callbacks are also more responsive to resume quality for White names than for African-American ones. The racial gap is uniform across occupation, industry, and employer size. We also find little evidence that employers are inferring social class from the names. Differential treatment by race still appears to still be prominent in the U.S. labor market.},
 author = {Marianne Bertrand and Sendhil Mullainathan},
 journal = {The American Economic Review},
 number = {4},
 pages = {991--1013},
 publisher = {American Economic Association},
 title = {Are Emily and Greg More Employable than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination},
 urldate = {2022-07-18},
 volume = {94},
 year = {2004}
}

@article{EDEL:LUCA:SVIR:17,
Author = {Edelman, Benjamin and Luca, Michael and Svirsky, Dan},
Title = {Racial Discrimination in the Sharing Economy: Evidence from a Field Experiment},
Journal = {American Economic Journal: Applied Economics},
Volume = {9},
Number = {2},
Year = {2017},
Month = {April},
Pages = {1-22},
DOI = {10.1257/app.20160213},
URL = {https://www.aeaweb.org/articles?id=10.1257/app.20160213}}

@article{HAN:LEE:19,
author = {Han, Sukjin and Lee, Sungwon},
title = {Estimation in a generalization of bivariate probit models with dummy endogenous regressors},
journal = {Journal of Applied Econometrics},
volume = {34},
number = {6},
pages = {994-1015},
doi = {https://doi.org/10.1002/jae.2727},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.2727},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.2727},
abstract = {Summary The purpose of this paper is to provide guidelines for empirical researchers who use a class of bivariate threshold crossing models with dummy endogenous variables. A common practice employed by the researchers is the specification of the joint distribution of unobservables as a bivariate normal distribution, which results in a bivariate probit model. To address the problem of misspecification in this practice, we propose an easy-to-implement semiparametric estimation framework with parametric copula and nonparametric marginal distributions. We establish asymptotic theory, including root-n normality, for the sieve maximum likelihood estimators that can be used to conduct inference on the individual structural parameters and the average treatment effect (ATE). In order to show the practical relevance of the proposed framework, we conduct a sensitivity analysis via extensive Monte Carlo simulation exercises. The results suggest that estimates of the parameters, especially the ATE, are sensitive to parametric specification, while semiparametric estimation exhibits robustness to underlying data-generating processes. We then provide an empirical illustration where we estimate the effect of health insurance on doctor visits. In this paper, we also show that the absence of excluded instruments may result in identification failure, in contrast to what some practitioners believe.},
year = {2019}
}

@Book{GREE:18,
  author = 	 {Greene, William},
  title = 	 {Econometrics analysis},
  chapter = 	 {},
  publisher = 	 {Pearson},
  year = 	 {2018},
  edition = {8th}
}

@article{ABIA:MODY:05,
Author = {Abiad, Abdul and Mody, Ashoka},
Title = {Financial Reform: What Shakes It? What Shapes It?},
Journal = {American Economic Review},
Volume = {95},
Number = {1},
Year = {2005},
Month = {March},
Pages = {66-88},
DOI = {10.1257/0002828053828699},
URL = {https://www.aeaweb.org/articles?id=10.1257/0002828053828699}}


@article{WERN:99,
 ISSN = {07350015},
 URL = {http://www.jstor.org/stable/1392405},
 abstract = {Dichotomous-choice contingent-valuation data are modeled using a mixture distribution. The standard parametric survival model is modified such that respondents in the lowest willingness-to-pay category may have either zero willingness to pay or a small positive willingness to pay. In comparison to the standard model, the mixture model leads to a dramatic reduction in estimates of mean willingness to pay. Covariates such as income are found to be more significant in determining the positive portion of the distribution of willingness to pay.},
 author = {Megan Werner},
 journal = {Journal of Business & Economic Statistics},
 number = {4},
 pages = {479--486},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Allowing for Zeros in Dichotomous-Choice Contingent-Valuation Models},
 urldate = {2022-08-15},
 volume = {17},
 year = {1999}
}

@article{CARS:WILK:IMBE:94,
 ISSN = {00307653, 14643812},
 URL = {http://www.jstor.org/stable/2663496},
 abstract = {The Australian Resource Assessment Commission conducted a large contingent valuation study to estimate the economic benefits of preserving Kakadu Conservation Zone (KCZ) by incorporating it into Kakadu National Park rather than allowing mining in it. Different subsamples were presented, with scenarios representing the environmentalist (major) and mining industry (minor) views of the impacts. Willingness to pay to prevent the major impact scenario was twice as high as for the minor impact scenario. For both scenarios, benefit-cost analysis indicates that preservation should be chosen over mining. A valuation function to predict the willingness to pay responses is estimated.},
 author = {Richard T. Carson and Leanne Wilks and David Imber},
 journal = {Oxford Economic Papers},
 pages = {727--749},
 publisher = {Oxford University Press},
 title = {Valuing the Preservation of Australia's Kakadu Conservation Zone},
 urldate = {2022-08-15},
 volume = {46},
 year = {1994}
}

@article{WANG:21,
Author = {Wang, Tianyi},
Title = {Media, Pulpit, and Populist Persuasion: Evidence from Father Coughlin},
Journal = {American Economic Review},
Volume = {111},
Number = {9},
Year = {2021},
Month = {September},
Pages = {3064-92},
DOI = {10.1257/aer.20200513},
URL = {https://www.aeaweb.org/articles?id=10.1257/aer.20200513}}

@article{FERR:CRIB:04,
author = { Silvia   Ferrari  and  Francisco   Cribari-Neto },
title = {Beta Regression for Modelling Rates and Proportions},
journal = {Journal of Applied Statistics},
volume = {31},
number = {7},
pages = {799-815},
year  = {2004},
publisher = {Taylor & Francis},
doi = {10.1080/0266476042000214501},

URL = { 
        https://doi.org/10.1080/0266476042000214501
    
},
eprint = { 
        https://doi.org/10.1080/0266476042000214501
    }
}


